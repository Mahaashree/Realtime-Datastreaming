# Telegraf Configuration for Real-time Data Streaming PoC
# This configuration collects MQTT vehicle data and system metrics

[global_tags]
  # Add tags that apply to all metrics
  environment = "production"
  project = "realtime-datastreaming"
  collector = "telegraf"

# Configuration for Telegraf agent
[agent]
  interval = "1s"  # Default data collection interval
  round_interval = true
  metric_batch_size = 1000
  metric_buffer_limit = 10000
  collection_jitter = "0s"
  flush_interval = "1s"
  flush_jitter = "0s"
  precision = ""
  hostname = ""
  omit_hostname = false
  debug = true


# MQTT Consumer Input Plugin - Collects vehicle speed data
[[inputs.mqtt_consumer]]
  # MQTT Broker configuration (use tcp:// scheme)
  servers = ["tcp://${MQTT_BROKER_HOST}:${MQTT_BROKER_PORT}"]
  
  # Topics to subscribe to (wildcard for all vehicle devices)
  topics = [
    "device/data/+",
    "vehicle/speed/+"
  ]
  
  # QoS level (1 = at least once delivery)
  qos = 1
  
  # Client ID
  client_id = "telegraf-mqtt-collector"
  
  # Connection timeout
  connection_timeout = "30s"
  
  # Persistent session
  persistent_session = true
  
  # Data format - JSON
  data_format = "json"
  
  # JSON timestamp format
  json_time_key = "timestamp"
  json_time_format = "unix"
  
  # Tag keys (will be used as InfluxDB tags)
  tag_keys = ["device_id"]
  
  # Field keys (will be used as InfluxDB fields)
  # Automatically extracts all other fields

  # JSON string fields (for nested objects)
  json_string_fields = ["detection_label"]
  
  # Override measurement name to match Python collector
  name_override = "device_data"

# Process flat JSON structure - convert types and move detection_label to tag
[[processors.starlark]]
  source = '''
def apply(metric):
    # Convert integer fields to int (always convert to fix schema collision)
    # Telegraf JSON parser may infer them as float, but Python collector writes as int
    int_fields = ["memory_total", "memory_used", "memory_available", 
                   "disk_total", "disk_used", "disk_free",
                   "network_bytes_sent", "network_bytes_recv"]
    for field in int_fields:
        if field in metric.fields:
            val = metric.fields[field]
            # Always convert to int (Starlark doesn't support try/except)
            metric.fields[field] = int(val)
    
    # Convert detection_label from field to tag
    if "detection_label" in metric.fields:
        metric.tags["detection_label"] = str(metric.fields["detection_label"])
    
    return metric
'''
# System CPU metrics
[[inputs.cpu]]
  percpu = true
  totalcpu = true
  collect_cpu_time = false
  report_active = false

# System Memory metrics
[[inputs.mem]]

# System Disk metrics
[[inputs.disk]]
  ignore_fs = ["tmpfs", "devtmpfs", "devfs", "iso9660", "overlay", "aufs", "squashfs"]

# System Disk I/O metrics
[[inputs.diskio]]

# System Network metrics
[[inputs.net]]

# System Kernel metrics
[[inputs.kernel]]

# System Process metrics
[[inputs.processes]]

# Docker container metrics - DISABLED (permission issues in containerized environment)
# [[inputs.docker]]
#   endpoint = "unix:///var/run/docker.sock"
#   container_name_exclude = []
#   container_name_include = []
#   container_state_exclude = []
#   container_state_include = []
#   timeout = "5s"
#   perdevice_include = ["cpu", "blkio", "network"]
#   total = false
#   docker_label_exclude = []
#   docker_label_include = [] 
# InfluxDB v2 Output Plugin
[[outputs.influxdb_v2]]
  urls = ["${INFLUXDB_URL}"]
  token = "${INFLUXDB_TOKEN}"
  organization = "${INFLUXDB_ORG}"
  bucket = "${INFLUXDB_BUCKET}"
  
  # Write options
  timeout = "5s"
  content_encoding = "gzip"

# Optional: Log output for debugging
# [[outputs.file]]
#   files = ["stdout"]
#   data_format = "json"

